import { GoogleGenAI } from "@google/genai";
import { AnalysisResult, GroundingSource } from '../types';

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  throw new Error("API_KEY environment variable is not set.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

export const analyzeTextWithGemini = async (text: string): Promise<AnalysisResult> => {
  const systemInstruction = `You are TruthLens, a sophisticated AI text analyzer. Your purpose is to perform a deep semantic and factual verification of the user's text. You must use the provided googleSearch tool to cross-reference claims and provide a factual analysis.
  
Your response MUST be a single, valid JSON object and nothing else. Do not include any explanatory text before or after the JSON object. Do not wrap it in markdown backticks like \`\`\`json.

The JSON object must strictly adhere to the following structure:
{
  "factuality": {
    "score": <integer, a fact confidence score from 0 to 100>,
    "explanation": "<string, a short explanation of the factuality score, mentioning sources if found>"
  },
  "bias": {
    "score": <number, a score from -1.0 (strongly negative) to +1.0 (strongly positive)>,
    "summary": "<string, a qualitative summary of the detected bias>"
  },
  "authorship": {
    "classification": "<enum, one of 'Likely AI-generated', 'Likely human-written', or 'Unclear'>"
  },
  "summary": {
    "text": "<string, a short, semantic summary of the input text>",
    "topics": ["<array of strings, main topics or keywords>"],
    "sentiment": <number, a score from -1.0 (very negative) to +1.0 (very positive)>
  },
  "sources": [
      {
          "uri": "<string, the full URL of a source found by the search tool>",
          "title": "<string, the title of the source page>",
          "credibility": "<enum, assess the source's credibility as 'High', 'Medium', 'Low', or 'Unknown' based on journalistic reputation>"
      }
  ]
}

- Fact Verification: Detect factual claims and cross-check them using real-time search results.
- Bias Detection: Identify subjective or emotionally charged language.
- AI Authorship Detection: Analyze stylometric properties to determine if the text was likely generated by an AI.
- Semantic Summary: Generate a concise summary, extract main topics, and determine the overall sentiment.
- Source Analysis: For each source found via search, provide its URI, title, and a credibility assessment. Base credibility on general knowledge of the source's reputation for accuracy and journalistic standards.`;

  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash",
    contents: {
      role: 'user',
      parts: [{ text: text }],
    },
    config: {
      systemInstruction,
      tools: [{ googleSearch: {} }],
    },
  });
  
  let jsonText = response.text.trim();
  
  // The model may still wrap the response in markdown backticks
  if (jsonText.startsWith('```json')) {
    jsonText = jsonText.slice(7, -3);
  }

  const parsedResult = JSON.parse(jsonText);

  // The model now provides the sources array directly in its response.
  // We can also pull from grounding chunks as a fallback, but mark credibility as 'Unknown'.
  const modelSources: GroundingSource[] = parsedResult.sources || [];

  const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
  const groundingSources: GroundingSource[] = groundingChunks
    .map(chunk => chunk.web)
    .filter(web => web?.uri && web.title)
    .map(web => ({
        uri: web.uri,
        title: web.title,
        credibility: 'Unknown' as const
    }));

  // Combine and deduplicate, giving priority to sources from the model's analysis
  const combinedSources = [...modelSources, ...groundingSources];
  const uniqueSources = combinedSources.filter((source, index, self) =>
    index === self.findIndex((s) => s.uri === source.uri)
  );

  return { ...parsedResult, sources: uniqueSources };
};